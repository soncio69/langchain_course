{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "88ed3f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c0203cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langchain-core) (0.1.120)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langchain-core) (2.7.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langchain-core) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langchain-core) (4.11.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core) (3.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.18.2)\n",
      "Requirement already satisfied: anyio in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e9fd7",
   "metadata": {},
   "source": [
    "Per utilizzare PineconeVectorStore è necessario installare le librerie \"partner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "59bcff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-pinecone pinecone-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c5ce0a",
   "metadata": {},
   "source": [
    "Quando si hanno testi lunghi è necessario splittarli.\n",
    "\n",
    "Langchain consente di utilizzare document loader per ogni tipo di documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "05f57376",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"files/churcill_speach.txt\") as f:\n",
    "    churcill_speach = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b9797",
   "metadata": {},
   "source": [
    "Utilizzando il RecursiveCharacterTextSplitter, suddivido il testo il chunks di lunghezze 100 e con 20 char di sovrapposizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "261a7192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Winston Churchill Speech - We Shall Fight on the Beaches\\nWe Shall Fight on the Beaches\\nJune 4, 1940'\n",
      "page_content='June 4, 1940\\nHouse of Commons'\n",
      "page_content='From the moment that the French defenses at Sedan and on the Meuse were broken at the end of the'\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    "\n",
    ")\n",
    "\n",
    "chunks = text_splitter.create_documents([churcill_speach])\n",
    "print(chunks[0])\n",
    "print(chunks[1])\n",
    "print(chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "57f8dc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ottengo 300 chunks\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ottengo {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f5431",
   "metadata": {},
   "source": [
    "## TIKTOKEN (per modelli OpenAI)\n",
    "Definisco una funzione per verificare quanti token verranno ottenuti utilizzando il modello di OpenAI (che però non useremo successivamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "05ce89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def print_embedding_cost(texts):\n",
    "    enc = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f\"NUmero di tokens : {total_tokens}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "60ad724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero di tokens : 4820\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a099b",
   "metadata": {},
   "source": [
    "Invece di utilizzare OpenAI come embedding model (text-embedding-ada-002), provo ad usare sentence transformer\n",
    "\n",
    "Prima devo installare la libreria con\n",
    "\n",
    "pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12ba1c",
   "metadata": {},
   "source": [
    "## EMBEDDING con HuggingFace\n",
    "\n",
    "HuggingFaceEmbedding¶\n",
    "\n",
    "The base HuggingFaceEmbedding class is a generic wrapper around any HuggingFace model for embeddings.<br>\n",
    "All embedding models on Hugging Face should work. You can refer to the embeddings leaderboard for more recommendations.\n",
    "\n",
    "This class depends on the sentence-transformers package, which you can install with pip install sentence-transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "683abaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "42cbd612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "#model_name='DeepMount00/Anita'  # Specializzato per la lingua italiana\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1f2c5de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={'device': 'cpu'}, encode_kwargs={'normalize_embeddings': False}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b823b",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Provo ad ottenere embeddings del primo chunk del testo precedentemente trattato. <br>\n",
    "Ottengo la dimensione dell'embedding vector ottenuto (che varia a seconda del modello).<br>\n",
    "Questa dimensione viene memorizzata in una variabile che verrà successivamente utilizzata per creare l'indice di Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4d3db447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.embed_query(chunks[0].page_content)\n",
    "embedding_dim = len(embeddings)\n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30c71e",
   "metadata": {},
   "source": [
    "## Pinecone\n",
    "\n",
    "Dopo aver importato le librerie, creo un pinecone Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "aaf43ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "pc = pinecone.Pinecone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71afac7",
   "metadata": {},
   "source": [
    "Creo un Pinecone Index. Dal momento che il piano gratuito consente un solo indice, devo prima cancellare quello esitente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bef05203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancello tutti gli indici\n",
      "Cancellato indice churcill\n"
     ]
    }
   ],
   "source": [
    "for i in pc.list_indexes().names():\n",
    "    print(f\"Cancello tutti gli indici\", end=\"\\n\")\n",
    "    pc.delete_index(i)\n",
    "    print(f\"Cancellato indice {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430fec1",
   "metadata": {},
   "source": [
    "Ri-creo l'indice con la dimensione corretta per l'embedding dimension ottenuta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0942c3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creo indice {index_name}\n",
      "iNDIC CREATO\n"
     ]
    }
   ],
   "source": [
    "index_name = \"churcill\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(\"Creo indice {index_name}\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=pinecone.PodSpec(\n",
    "            environment=\"gcp-starter\"\n",
    "        )\n",
    "    )\n",
    "    print(\"iNDIC CREATO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d7a0a",
   "metadata": {},
   "source": [
    "## Creazione Pinecone vector store\n",
    "    \n",
    "The PineconeVectorStore class provided by LangChain can be used to interact with Pinecone indexes.<br>\n",
    "It’s important to remember that you must have an existing Pinecone index before you can create a PineconeVectorStore object.\n",
    "\n",
    "To initialize a PineconeVectorStore object, you must provide:\n",
    "- the name of the Pinecone index\n",
    "- an Embeddings object initialized through LangChain.\n",
    "\n",
    "There are two general approaches to initializing a PineconeVectorStore object:\n",
    "- Initialize without adding records\n",
    "- Initialize while adding records\n",
    "\n",
    "Vedi https://docs.pinecone.io/integrations/langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a387030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df9b8c",
   "metadata": {},
   "source": [
    "## Inserisco i documenti nel vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4822a752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d7ffe132-edcd-4c13-838a-5adf084045a8',\n",
       " '1443c9f0-94d8-46e4-bf61-de24f776e333',\n",
       " 'ef6ea78d-c068-4b3c-8688-6ccf22b1b5b3',\n",
       " '542832f2-d325-47e8-b536-96670e20c250',\n",
       " '8d252fbe-7b73-4c39-8f72-d4a3a25504a3',\n",
       " '2a700138-c8d3-47e9-a034-3e4d9a8573f0',\n",
       " '7d7a8050-b87c-4dd5-8515-6e91226e2fab',\n",
       " 'd07763dd-c30e-49b4-bdd1-49f1bb2ef547',\n",
       " '66a8c90e-da03-4563-b2c1-146e1a25cb17',\n",
       " '676bb008-ea67-4490-b6aa-3982ff154491',\n",
       " '64499a62-e4ff-4b49-bc52-402cf7d22d22',\n",
       " '90209b63-2bc3-4b22-b46d-6b8edfe4a9c3',\n",
       " '4f394077-7595-4fec-8c49-162e570ee902',\n",
       " '2c453581-452b-4932-ac4f-8f5eabb0836d',\n",
       " '8c7d6512-0b7b-437c-874b-ea06662271a7',\n",
       " '94e540b2-fb5f-4947-9c55-71208373cc87',\n",
       " '1a899313-4ad8-4aa4-a920-95d237128770',\n",
       " '275013ab-1f42-41c4-8bbb-ffe828ced55f',\n",
       " 'dde43138-0bb0-4ef5-92cb-9812b4176adf',\n",
       " 'f0f72db2-58c8-4aa8-b150-268f74ca5247',\n",
       " '28078d88-af3d-41aa-943b-bdfc36525b29',\n",
       " 'c895b796-824a-421d-a464-82e715308ee7',\n",
       " 'aa976b6a-f79a-4059-813a-218fd15abe86',\n",
       " '151ad8c8-eb8e-4387-9258-b9f0b7d8b55e',\n",
       " 'ab30dfb3-795f-405a-a133-76398b1d9399',\n",
       " '45e8ec60-1f63-4c8e-95e8-d1cef08238a7',\n",
       " 'fa0d79e1-8a7d-4b04-a452-3c0d6d8674e2',\n",
       " '2f8af312-9b10-4e0e-b6b6-810ed0aaa924',\n",
       " 'b01d61ed-6e2a-4efe-9467-f5fd278e7baf',\n",
       " '323a2f47-9de3-4951-b5a1-7a38124a1ab6',\n",
       " '012c176c-35e8-4748-8a89-029542af9fd0',\n",
       " '87ec5301-179b-44c3-b8ae-7eddaec0a102',\n",
       " 'c2ac1a43-b871-430a-932a-9de684884bdb',\n",
       " '6f775f2f-26c9-4e51-9281-0b2b048fc6c0',\n",
       " '7483923e-2296-4dc6-bc47-e8712574d4e9',\n",
       " '652bae20-75cc-4254-a879-62158a3e844f',\n",
       " 'fc6b24f1-ed56-4857-bfad-104a5e9baa18',\n",
       " '90a00f06-2313-40cc-8f1a-b3682e244e2c',\n",
       " 'a28d8376-8784-4615-863c-60f9c0daa3a6',\n",
       " '95deb491-f7e5-46b7-955a-0c7845fa73ef',\n",
       " '49dd2743-19d0-4f99-9556-e7a612bbaa92',\n",
       " '4c182f63-76d6-450e-8d68-1398a5fdb6b5',\n",
       " 'f26b1642-0e88-447a-b7fa-26661fe674f4',\n",
       " '73510322-3854-44e3-94da-208f8550afa3',\n",
       " '662207db-75f3-4b21-a730-54670a4b2196',\n",
       " 'bc520528-b35e-43bf-a9ed-203ddf5f2327',\n",
       " '35678e0c-aa22-4fd5-9149-b46bbcc4b510',\n",
       " '53403e1b-9f6f-4cf2-b4e1-336727267a02',\n",
       " '6fbf5623-4050-4c45-b7be-7f9f013276d7',\n",
       " 'bec15b06-863a-4f84-82d9-daf75df6d9bf',\n",
       " '1a89cb20-6ddc-4813-afee-2cf4f1751f17',\n",
       " 'e47cfa15-8e7b-4a01-9ef3-3c274402086e',\n",
       " 'e489aeed-f063-4201-ae4a-1b6461c341b1',\n",
       " '0baa125c-45c9-4d79-81ed-54afcd219b82',\n",
       " '332dfc48-ecfd-465b-bf59-41e406f5fabd',\n",
       " '0e429aee-8102-458a-85be-4d357f0d13bb',\n",
       " 'cbc06bd6-3056-4ad7-bdb1-327f974a301e',\n",
       " '5b09e58d-6f6b-4b0a-8489-0484efee395e',\n",
       " '48c75c72-c4dc-4eb3-bf3e-678c61c78991',\n",
       " '94879050-e6a0-46c3-bbac-77c5935567c2',\n",
       " '077765d5-1f88-4fc7-9368-cb5a91a39204',\n",
       " '026a0836-80e9-4057-8841-80deffba4a76',\n",
       " '4e875ba0-fbcd-4c28-9387-95c0547fc4e5',\n",
       " '3a8d4e77-5ebe-4bbe-b79a-9c08ddcaaaf7',\n",
       " 'c1f5c607-736c-492f-974f-d1cfdacadc34',\n",
       " '640cf667-3598-45c5-9721-e019abf6b7d1',\n",
       " 'ffb5e36a-ba18-4af5-a395-c9ae89d3fbdd',\n",
       " '0c1707cf-c2b7-4c41-a732-b7d8534fd1a9',\n",
       " '67ec92a1-b88f-4641-8e6a-c145cb7af7c2',\n",
       " '81bbe206-a10a-4cfd-9798-5f8b674d0655',\n",
       " 'ad63725a-115d-4b49-bcb0-23c55a71e712',\n",
       " 'de696698-7156-4e1c-9e3d-e08d2a7c63ff',\n",
       " 'a825cb2d-019f-41ce-972f-4c25abe689f7',\n",
       " '3d9190ab-7799-4a00-a982-1601665c7baa',\n",
       " '55837253-a7fa-43da-8d66-c412809f266d',\n",
       " '70fd4d64-f0de-405c-8ac6-945f49625503',\n",
       " '3c4a7782-f468-4b03-9818-13b7dabb5af3',\n",
       " '1045f5e9-e435-4dce-a30d-c95fcd28c8bb',\n",
       " '24960b9e-06f5-440a-bacf-1d0640a6498f',\n",
       " '67cdd105-3e90-4002-bfff-dd0fc512de0a',\n",
       " '4d0ebeb1-ff25-4db6-a4a8-c890ec70e895',\n",
       " '3df85edb-ae0b-4ad2-85e5-fd3007842d41',\n",
       " '19b5f036-a465-4d43-9740-b8dbfe7742cb',\n",
       " '48110056-53bc-46da-b749-24d372ca5258',\n",
       " 'b75d8444-506a-4ac6-b7d1-69862bc5584a',\n",
       " 'cc187997-21a0-40a0-b65d-a3222ee3e498',\n",
       " 'befd3d25-44c4-4e97-a7cc-7950f512e421',\n",
       " 'a5362d9b-cfde-4ac1-9786-5cf01ef316d4',\n",
       " 'afba7242-b45a-4016-a759-e757f95ba7ba',\n",
       " 'b95ee76e-5eb8-49e6-8b83-288fb7d4dc59',\n",
       " 'c7339ad4-022e-48de-915d-3255c2794e37',\n",
       " 'cff141ed-0309-4abd-9f18-d84cc5a34c15',\n",
       " '0cfd4530-57a3-4108-b975-d47317c43d29',\n",
       " '67063eed-5efc-4a67-8fe4-0c7e38d88074',\n",
       " 'b2039c56-ddd8-4f88-b16f-e2853238c59e',\n",
       " '527eb0d7-e0b8-498a-8f24-debfb1a83606',\n",
       " 'ae6fb950-0f01-43b5-b869-c3a17eb77c95',\n",
       " '127342b6-e829-42e1-b2bd-7ecb8c155667',\n",
       " 'eb686f95-b501-4430-8ad7-14adfb17d64e',\n",
       " '5293744d-b08c-4b1e-907f-897f9a63d99f',\n",
       " '9ee369d2-4182-44b3-badb-16095d27934b',\n",
       " '0e42a903-9d68-4fb3-9338-7e67182075e4',\n",
       " '0272cafd-2124-453f-97f3-afd9a9a2d5b1',\n",
       " 'e1d9d683-d38e-4b18-9937-5d815bb0ca76',\n",
       " '318fa26c-dfe3-43c6-b502-715b4fc58339',\n",
       " 'd61e2ccf-166a-4b6f-af05-69cc9bbd7015',\n",
       " '914741e5-c547-446c-b6e7-b7774f587791',\n",
       " 'd3430af0-48d5-4411-96bd-23e94d1b1d15',\n",
       " '7461f2b6-9174-4f49-8a38-0a5fa326bd4f',\n",
       " '8e6eadba-5511-434a-9c14-14c4aa5770e2',\n",
       " '246b3f78-8381-4989-b8bd-ad2b8f202612',\n",
       " 'b836df83-2060-4d51-b0cc-b8b97336f4a5',\n",
       " '0a40c202-d3b6-45c9-bac8-b457d4696e18',\n",
       " '55626982-161e-4018-8c4f-cb809535ddfc',\n",
       " '66ded1c9-fd8b-45ea-ad6c-ddfc916d6364',\n",
       " '681e6b1d-af47-4c13-add9-d3daddec62b1',\n",
       " '64d9599f-2a77-421c-b549-a8cbb3ec98c0',\n",
       " 'c07b6930-3b48-4b9f-a240-b576c907d87c',\n",
       " 'b166ff6c-4ae0-4c08-9696-fe09de484720',\n",
       " 'e235513b-35fe-462c-a557-e71c4d8c449f',\n",
       " 'd9174849-5d65-4b75-a9cd-e8eb52896fab',\n",
       " 'ce24d302-abfa-412b-8a00-cedae46f24de',\n",
       " '90be83a3-d395-47ca-afe3-871f15251af1',\n",
       " 'a02d4837-ef88-4db2-bc27-ab25a4ae0738',\n",
       " '74668433-9c88-4cde-b5ba-7095da3629c9',\n",
       " '833fde46-f2fb-43ef-96be-ea3efb3be28e',\n",
       " '7449768e-e86b-48f4-bd51-1ccfe4341aec',\n",
       " '8851c135-a22d-4c58-99bb-08eb157c482f',\n",
       " '6bee0f56-4bb1-4ae7-9048-edc398d86fdd',\n",
       " '20b486bb-2ce2-4be8-a21c-554d4a415294',\n",
       " '2ddc1bbb-cd16-4a11-ac0c-63d19a8cc5e1',\n",
       " 'a0414295-e38a-48ac-abaa-f307cbe48afe',\n",
       " '93bdf3b2-9627-46d8-8c77-be636d8b9bf1',\n",
       " 'b4833c1a-405c-4162-a481-28d1eb91a707',\n",
       " '12a25a79-f5b1-4660-b48a-913c7e31ec76',\n",
       " 'fb7a9c65-aa19-483f-9a9b-c9d411df586a',\n",
       " '0ed824cf-0420-4852-948e-ffd1012986a5',\n",
       " 'd01874ba-edc3-4e9b-84e1-222cea4e5b53',\n",
       " 'f9f8f985-02b6-4d7e-937b-93dbb0c0dfbb',\n",
       " '08506aa2-aa0b-4dd7-8404-627d1b31e776',\n",
       " '4d5b5d1d-9df7-468b-a65f-b2a5ef44d110',\n",
       " '490a8ce6-0f5a-4f7b-8307-cbfbaea309ad',\n",
       " '535ea3c0-d228-47ad-8c8f-e4ab6ff57ad1',\n",
       " 'edc1628a-3964-4360-b2a0-336c77617f0b',\n",
       " 'dc35b127-9534-4208-91d2-0c5ffd470be4',\n",
       " '946a4e1e-17e9-41ac-babb-1c4b8ffbb867',\n",
       " '32df5d8b-8039-4de2-84ac-97d6a8c74607',\n",
       " '8d830479-92be-4602-946f-4a52dc5f6483',\n",
       " '90de2025-b72d-49b1-b548-b9e6c02af4e3',\n",
       " '3053d025-2ca6-457c-b205-81960d9de394',\n",
       " '03551bfb-14bb-4256-a224-4031f09e7a54',\n",
       " '072fe500-2b04-4239-85e1-eab9fd773db5',\n",
       " '36f23410-0b3f-4716-a206-234fd8f747fd',\n",
       " '490c8664-92ca-4870-8d59-d4f1195828b0',\n",
       " '03f6135f-0d06-4a99-bab8-6ae1b31ab910',\n",
       " 'd58d3202-11ae-4bb0-b8c4-8520c9606155',\n",
       " '6a073fdc-405b-4d85-a4f5-a70c8b9357ec',\n",
       " '59c674ca-3df7-49ea-a1de-6121282b6aac',\n",
       " '3068e653-ce9e-46f3-a99e-a0c7e69068e8',\n",
       " 'd4e2996c-730c-4e04-8c44-b41287a6cb6e',\n",
       " '13656fc5-fc05-410c-b855-050247d629e8',\n",
       " 'd67ac564-9931-4878-a8f1-4b750c47c01a',\n",
       " 'abae8ae7-e01b-446e-b2ab-ae8436704226',\n",
       " 'd19f3ead-2310-46c8-879a-e2321465d1bf',\n",
       " 'b391ea6e-6232-4e27-9894-f3c0b3b7122b',\n",
       " '545c7b12-3eef-44a6-a368-d74058a649d6',\n",
       " 'f367053b-265f-484b-ad1d-9ddfe3b39042',\n",
       " 'f326c876-b406-4861-8b44-142135b03a78',\n",
       " 'c49ca675-3084-4175-a6de-dbba60a619f8',\n",
       " 'f10e5946-7eb6-4b52-b3f6-d06628adf0b8',\n",
       " '8067e09f-8490-4f41-86b1-91fa58f92e8d',\n",
       " '99aa5ef5-aa5a-4da4-9dfd-a431f59e04d7',\n",
       " '963b91cb-59b0-4603-8c26-839819c50888',\n",
       " '439861c3-dcd9-4bac-af02-3c8ec5f17acb',\n",
       " 'b7d5c586-2971-4cc7-8ddc-6bcbf81d2fea',\n",
       " 'a81dc923-4f55-4105-965d-2e9d9c7ec42b',\n",
       " '572d7b4d-70ba-49ce-ad21-bc48b3473d93',\n",
       " '1648b46a-f02b-414a-a121-36ccef9d3c3b',\n",
       " '605229e5-82fb-4922-ada7-0d15751fe330',\n",
       " '00c3e8ad-3ccc-46ae-a2a0-a3db36f11fea',\n",
       " '45a65027-8138-4b1e-b659-5094b885cf71',\n",
       " '834ac1f1-039f-4f41-b44b-11b30703552c',\n",
       " '7cd42442-5b9e-4bb8-886d-eb79ffa3c44c',\n",
       " 'a8d0542f-c8f9-4b09-a388-e711a935d7f7',\n",
       " '7c22c3b8-fdb7-4581-9478-393a10504c49',\n",
       " 'fe5b9859-711f-49ab-9400-fe4f2cfbd0b9',\n",
       " 'c719fe1c-49d2-4254-8058-09650bbfe20a',\n",
       " 'f6ad4e6f-7a21-44d5-95e7-7ce531a87e3f',\n",
       " 'aafff889-a655-4400-8193-6c4f1cbc15ef',\n",
       " 'eb293349-bee7-4ed5-8492-c9d76983f568',\n",
       " '4a5685f7-8a6c-4ae1-81e1-50041bbbe438',\n",
       " '7f9c2f0d-e1a5-4598-8865-2b17ada7f69d',\n",
       " 'e909c559-6d8d-4007-b0c8-6d94fdde04df',\n",
       " '144408ec-4b86-4b93-86f0-05f91981690e',\n",
       " '7c69cfd6-be33-4579-966d-b18f3c7aa95a',\n",
       " '14ea5308-e271-4dd6-bf76-570d1dde5cf0',\n",
       " 'ee2a14ee-a07c-43a8-ad70-900a6e882845',\n",
       " 'c50dc2f6-5096-4e76-9e86-da3642178920',\n",
       " 'f4cd4cc8-2ab6-4d99-9342-b04273931d96',\n",
       " 'b1fd7ff0-3a17-47e5-80d7-4c379286a910',\n",
       " '3738cd8c-283b-4829-b546-61184c72f188',\n",
       " 'eef00b15-cd11-4932-b49e-97f0e42e06eb',\n",
       " '5bdccac8-3866-465a-ad36-2b7484ddd843',\n",
       " '8cdf6caf-afed-4bbb-a2d0-941067d6c581',\n",
       " '5749f786-ca83-4589-80f3-55fee530b44c',\n",
       " 'a615ca62-72b8-4619-a153-21c5b50e0a3d',\n",
       " 'ade48423-2970-45fe-9627-5a5c042b20d8',\n",
       " '0286b955-c39b-4c9e-9d90-ed1d43d8a6b2',\n",
       " 'c666507e-cc9b-4b1b-a7aa-3ee3720e8426',\n",
       " '9a2877ae-4e65-45d7-87bc-2c3ae823c4f7',\n",
       " '5d20bb26-3889-422a-87e0-346f21f72fdc',\n",
       " 'e12972fd-89e6-4bfe-a307-b8213175e05f',\n",
       " '50cd0681-b066-4b5c-b729-fb55fde29d41',\n",
       " '1ae3979a-b5d3-40a0-8fc8-0df1ff475e8b',\n",
       " '155ecc3a-4b16-4fb0-b40d-964ba8b9a0d5',\n",
       " '3327bc3b-0776-4a50-8424-5616a7caa810',\n",
       " '84358db7-c5fb-45e7-bcdd-e3d08ea65d30',\n",
       " '8dbf768d-d068-4751-b44f-764706983171',\n",
       " '114b4f96-3cb7-419b-8902-991cca15c0f3',\n",
       " '487b00e7-2eff-4bc5-b5b7-55dee4f21736',\n",
       " '081c80bc-82a8-4336-9099-37edcd4a942d',\n",
       " '8bc56a30-562e-47ce-813d-f42504ba71e2',\n",
       " '157e6ef1-9e69-4c9e-a04f-7864f85c7b11',\n",
       " 'e7d79a2e-1da7-4f37-b04e-11708c71e34a',\n",
       " 'eabccb09-fea2-43c7-9d4b-4e93b01f00a2',\n",
       " '6b6c8ce5-a53c-4c19-8efd-e5bb391213c7',\n",
       " '93325fe3-d71b-4ec7-b407-04cc69f2aad3',\n",
       " '040a02c8-1733-482d-a069-5c1b3a0a089e',\n",
       " 'f97f2054-9431-45be-8531-5c459a3952aa',\n",
       " 'a5750888-0b4c-46be-ae1a-b06bf29f1fdd',\n",
       " '60e0ac8f-e57c-44fd-9826-2070e22c37f1',\n",
       " '463bba03-5e56-420a-b06c-ee9925abc1cc',\n",
       " '187f51a6-761c-4c94-b55a-c3f0f4368e8e',\n",
       " 'c89c4abd-0041-44eb-984f-943d359f2cb8',\n",
       " '7aaa71e2-6f5f-4a23-b574-88ed2268a0bf',\n",
       " 'c1ebad45-5584-496a-898a-11dc2aefe79a',\n",
       " '101d554a-ee5e-4e82-9219-3018bc7eae6e',\n",
       " 'f0e47f00-707e-468a-b758-a7f7bc067455',\n",
       " '1b2254dc-c918-4082-9e33-2d704f19085d',\n",
       " '0758258e-a918-4b8e-94e1-05f1f31af170',\n",
       " 'aea131cf-3647-46c2-8b74-86f618f35938',\n",
       " '04ad27fb-b9d2-41b2-a49d-eb0a607fbb79',\n",
       " '3ad91a0d-4e22-4811-9a8f-8b9aa3ff67f0',\n",
       " '62cfebee-3b55-4446-b82f-c7c1136c534c',\n",
       " '75a27d83-8779-49d7-a288-e600e9b9cfab',\n",
       " 'a3af0a5c-3b2f-47a7-9f0f-9026c27cddf4',\n",
       " 'acf7afd6-39a4-4839-bbbe-21bd74fa3ecf',\n",
       " '1e4736ac-e026-4c29-ac33-b231c6c176fc',\n",
       " '9a16ecbe-4450-4dc2-9f7d-2acceee18bd0',\n",
       " 'b7874f80-6384-40da-a8be-3df6e403af8f',\n",
       " 'd8083b5c-3aaa-4920-a263-90f37e611894',\n",
       " 'd8f874e2-933f-4200-89d2-a5cf689d191c',\n",
       " '4b8b637e-4dd5-4eec-8511-2da5d2187ce7',\n",
       " '5484a8eb-ca9e-4f01-a7b3-ef2e45baf043',\n",
       " '2da9d6a2-da83-4636-ac8d-1a50f06980ce',\n",
       " 'd8cce12c-1971-4b80-992a-e597063fb09b',\n",
       " '50a18d3e-3f89-46a6-a899-40e852f64891',\n",
       " 'cad018b3-8a4c-4c52-83ee-bcb735978702',\n",
       " '82ee5553-a1be-495d-9a18-fe4f41ae29c0',\n",
       " '79cab89f-7afb-4fc1-8cec-1ede982be27f',\n",
       " '4902d01b-6755-43df-8b8d-f31d4cb6fe95',\n",
       " 'e18cacdc-113f-4106-8fbb-7ffa037d0414',\n",
       " '07bf2f3b-c09e-4862-9935-9edb5907ced5',\n",
       " '87ae7b75-bdc2-4f69-8f1a-f5ba6fdcd5af',\n",
       " '24945f3a-64de-40b1-a3ed-a50b9884426c',\n",
       " '9cb46983-d023-4607-b95d-0ee226803ebf',\n",
       " '61534c5d-cac8-482e-9672-589069aa0d73',\n",
       " 'de98d05f-7153-436c-81c2-55e3823ef7d5',\n",
       " 'c7e643aa-9dff-4951-bb8c-76e3293a8978',\n",
       " 'f0b0cf8c-a358-4b69-af61-cc89503722af',\n",
       " '252a5b6e-be92-49ef-90b5-09aacd072485',\n",
       " '0558eb2f-4ee3-4099-b8df-57486e314a45',\n",
       " '10e63420-701f-4648-9192-a1c5651a06de',\n",
       " '9fde0dfa-d776-441e-84a6-aced2707d336',\n",
       " '5624bec5-9967-4084-8dae-ab9a9a373dc4',\n",
       " 'db751527-77ae-4933-9a88-80973a6138b3',\n",
       " 'd4bc8b0e-8800-4462-8455-31db0c243ecc',\n",
       " '4a248541-96b0-4411-baab-214d36569d30',\n",
       " 'd371ef67-1c34-4e4b-9690-900c694b010d',\n",
       " '167d1a58-4a34-42bd-a405-9d751219c9e4',\n",
       " '062e4761-6507-4e49-86bd-2b7c3b09e450',\n",
       " 'd9fe161d-2b36-4c95-9901-7f33e30ab684',\n",
       " 'd76560bf-9df9-452c-894b-e1864af98333',\n",
       " '5049fdd5-0a10-4607-84d0-81000a9552ff',\n",
       " 'c6637a20-9b5d-4031-9db8-2ac7271ea176',\n",
       " '507eb203-2152-4a34-af32-e0ecb4394f5a',\n",
       " '59a64525-227f-4fd6-8f66-2930ec7aa866',\n",
       " 'dd68f88c-1d1b-4b3e-b6ac-5ebb0adff957',\n",
       " 'df8d9914-fb8a-489f-b721-5b6323309345',\n",
       " '38f0e9c6-101f-4d7e-95c7-9c9da8bdca6f',\n",
       " 'ff38e97a-f86c-4721-82a6-a0c7b54309d9',\n",
       " '1952d52b-41ba-47f3-a6b0-aed07f11a575',\n",
       " '1d3f478c-ba5e-4798-a3b5-90d5800534ed',\n",
       " 'fa36d7ff-2d6c-45c1-87ce-95df63c5994d',\n",
       " '0a713f6c-ce30-4576-8ab9-e3e23f6eaa82',\n",
       " 'f255aeb1-5486-4721-b4b2-a5272a50e64a',\n",
       " 'fd0ffb4f-1535-48f5-8fb5-8827d341a162',\n",
       " '5324f639-ff6d-409b-a2e2-6d0d940e6784',\n",
       " '77239c6c-e9d1-47d4-808a-4f3fc6cc6ec0',\n",
       " 'd5d3919b-0b3f-46ab-92b9-37c581b6a617']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(chunks))]\n",
    "\n",
    "vectorstore.add_documents(documents=chunks, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77475b",
   "metadata": {},
   "source": [
    "Per creare un vector store da un indice già esistente su Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "721b39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Pinecone.from_existing_index(index_name=\"churcill\", embedding=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df67400",
   "metadata": {},
   "source": [
    "## Similarity search\n",
    "\n",
    "Dopo aver creato la nostra knowledge base, è possibile utilizzarla per ricerche basate su similarity search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9504a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front, now on that, fighting\n",
      "I return to the Army. In the long series of very fierce battles, now on this front, now on that,\n",
      "shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and\n",
      "streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a\n"
     ]
    }
   ],
   "source": [
    "query = \"where should I fight?\"\n",
    "\n",
    "result = vector_store.similarity_search(query)\n",
    "\n",
    "# Visualizzo i risultati più simili al testo della query sulla base della metrica stabilita (cosine distance)\n",
    "for r in result:\n",
    "    print(r.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e54321c",
   "metadata": {},
   "source": [
    "Una volta estratti i risultati più simili alla query, è possibile passare questi risultati ad un LLM perchè questo fornisca la risposta finale in linguaggio naturale.\n",
    "\n",
    "A tal fine una opzione è quella di invocare un modello OpenSource esposto dal server OpenAI di llamacpp (vedi progetto ad hoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fde44b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        api_key='545454545',\n",
    "        base_url='http://localhost:8000/v1'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38909fda",
   "metadata": {},
   "source": [
    "DEvo quindi creare una chain apposta pre RAG. A tal fine creo un retriever utilizzando il vector store popolato con il testo di input ed i relativi embeddings.\n",
    "\n",
    "Una volta creato il retriever, creo la chain fornendo sia l'LLM che dovrà fornire la risposta finale che il retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "44f5be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={'k' : 3})\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c8659",
   "metadata": {},
   "source": [
    "Definisco la domanda ed invoco la chain fornendo la domanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "adfe7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"where should I fight?\"\n",
    "\n",
    "answer = chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "84dc5e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I can see that you are referring to a quote from a famous speech by Winston Churchill during World War II. The quote mentions several places where battles were fought during the war, including the beaches, landing grounds, and fields. However, it does not specify where you should fight in this particular situation. If you have a specific question or need further clarification, please let me know.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "06264053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, it seems that during a battle between the British and French Armies, the French First Army was captured and held by the British. However, without additional information, I cannot confirm whether the French Army as a whole was involved in the battle or if this refers specifically to the French First Army.\n"
     ]
    }
   ],
   "source": [
    "query = \"what about the french army?\"\n",
    "answer = chain.run(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa6eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain_env]",
   "language": "python",
   "name": "conda-env-langchain_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
