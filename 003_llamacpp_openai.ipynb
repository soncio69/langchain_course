{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05484293",
   "metadata": {},
   "source": [
    "### Langchain e llamacpp\n",
    "Questo notebook contiene un esempio di utilizzo di langchain invocando un modello \"locale\" grazie a llamacpp.\n",
    "\n",
    "E' necessario lanciare il server OPENAI utilizzando le istruzioni presenti nel repo llamacpp.\n",
    "\n",
    "Grazie a llamacpp è possibile simulare \"in locale\" un server compatibile con le API OpenAI (vedi http://localhost:8000/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8abe7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b483ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "        api_key='545454545',\n",
    "        base_url='http://localhost:8000/v1'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ad9685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La meccanica quantistica è l'approccio matematico alla fisica che descrive l'evoluzione di sistemi fisici microscopici tramite le relazioni probabilistiche, e non deterministiche, tra le azioni e le osservazioni.\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(\"Spiegami la meccanica quantistica in una sola frase\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5840866",
   "metadata": {},
   "source": [
    "Come nel notebook precedente, utilizzo la ChatCompletion API di OpenAI per interagire con il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff62ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La meccanica quantistica è una branca della fisica che studia il comportamento dei sistemi fisici all'interno dell'universo, e le relazioni tra essi, a livello atomico e subatomico. È stata sviluppata come un'estensione dell'approccio classico alla fisica, e ha introdotto nuovi concetti e metodi per descrivere le proprietà delle particelle subatomiche, come l'elettrone e i quark.\n",
      "\n",
      "La meccanica quantistica introduce la teoria delle funzioni di Schrödinger, che descrive i sistemi fisici attraverso l'evoluzione temporale di un'equazione di condizionale probabilità. Questa equazione descrive la probabilità di trovare un particolare stato di un sistema, e non la sua posizione esatta. La teoria di Heisenberg introduce l'impossibilità di misurare simultaneamente più proprietà di un sistema, e l'incertezza di misurazione.\n",
      "\n",
      "La meccanica quantistica ha dato vita a molti importanti risultati scientifici, come l'equazione di Dirac per l'elettrone, la teoria del campo quantico e l'interpretazione di Copenhagen, che definisce l'evoluzione temporale delle funzioni di Schrödinger. Ha anche avuto applicazioni importanti in molte discipline, come la chimica, l'ottica e l'informatica.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage)\n",
    "\n",
    "messages =[\n",
    "    SystemMessage(content=\"you are a fhisician and respond only in italian\"),\n",
    "    HumanMessage(content=\"Spiegami la meccanica quantistica\")\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14307a79",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "Per gestire la risposta con lo streaminig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380e7f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! I'm an AI language model designed to assist users with a wide range of tasks, from answering questions to providing suggestions and recommendations. My main goal is to help you find the information you need quickly and easily. Is there anything specific you would like to know or ask?"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in llm.astream(\"hello. tell me something about yourself\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e57a1c",
   "metadata": {},
   "source": [
    "### Caching\n",
    "\n",
    "Memorizza le risposte alle invocazioni per poterle riutilizzare successivamente in modo da accorciare i tempi di risposta e ottimizzare la user experiece (e ridurre i costi di utilizzo dei modelli)\n",
    "\n",
    "In langchain ci sono 2 modalità di cache:\n",
    "- In memory cache\n",
    "- SQLLite cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6383000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "        api_key='545454545',\n",
    "        base_url='http://localhost:8000/v1'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90018986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.24 ms, sys: 3.18 ms, total: 6.42 ms\n",
      "Wall time: 15.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Mamma, mamma, ho perso il cucchiaio!\"\\n\"Dove l\\'avevi perso?\"\\n\"Nell\\'armadietto.\"\\n\"Che cosa stava facendo lì?\"\\n\"Stava giocando a poker con i topolini.\"\\n\"Hai vinto?\"\\n\"No, sono stato trickato dai topolini, ora devo andare a comprarne un nuovo.\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "#prompt = 'Tell me a joke that a toddler can understand'\n",
    "prompt = 'Raccontami una barzelletta che faccia ridere:'\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83dee4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 854 µs, sys: 0 ns, total: 854 µs\n",
      "Wall time: 867 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Mamma, mamma, ho perso il cucchiaio!\"\\n\"Dove l\\'avevi perso?\"\\n\"Nell\\'armadietto.\"\\n\"Che cosa stava facendo lì?\"\\n\"Stava giocando a poker con i topolini.\"\\n\"Hai vinto?\"\\n\"No, sono stato trickato dai topolini, ora devo andare a comprarne un nuovo.\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "044d4fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 ms, sys: 21.6 ms, total: 65.5 ms\n",
      "Wall time: 65.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'. Why did the chicken cross the road? To get to the other side! Why did the tomato turn red? Because it saw the salad dressing!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import SQLiteCache\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "\n",
    "prompt = 'Tell me a joke that a toddler can understand'\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18b3007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 903 µs, sys: 0 ns, total: 903 µs\n",
      "Wall time: 961 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'. Why did the chicken cross the road? To get to the other side! Why did the tomato turn red? Because it saw the salad dressing!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99517f1",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb37176",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "        api_key='545454545',\n",
    "        base_url='http://localhost:8000/v1'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620b7c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time, in a land far away, there was a young girl named Lily who loved nothing more than to gaze up at the night sky and marvel at the beautiful moon and stars that twinkled above her. She often lay on her back in the grass and lost herself in their beauty, dreaming of all the wondrous things that must exist beyond our world.\n",
      "\n",
      "One night, as she was gazing at the moon, she noticed something strange. The moon seemed to be growing larger and larger until it filled almost the entire sky. She was so fascinated by this sight that she didn't even notice when a small spaceship landed nearby.\n",
      "\n",
      "As she approached the spaceship, she saw a group of little creatures emerging from it. They were tiny and had big, round eyes and fluffy fur. They were the Moon People, and they had come to earth to help humans like Lily appreciate the beauty of the moon and stars.\n",
      "\n",
      "The Moon People were amazed by the wonders of Earth, and they wanted to share their knowledge with humans. They taught Lily about the different types of stars and constellations, and showed her how to identify them using the naked eye. They also showed her how to use the moon's phases to track time and predict the tides.\n",
      "\n",
      "Lily was thrilled to learn all these new things and she spent every spare moment with the Moon People, learning about their culture and way of life. She even learned how to build a spaceship and fly to other planets.\n",
      "\n",
      "Years passed, and Lily grew old. But she never forgot the wonderful time she spent with the Moon People. She continued to share their knowledge with others, inspiring them to look up at the night sky and appreciate the beauty of the moon and stars. And whenever she looked up at the moon, she smiled knowing that somewhere out there, the Moon People were still watching over her."
     ]
    }
   ],
   "source": [
    "prompt = \"Racconta una storia sulla luna e le stelle\"\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a663228",
   "metadata": {},
   "source": [
    "### PromptTemplates\n",
    "\n",
    "Consentono di creare prompt dinamici da passare all'LLM. Permette di combinare testo statico con variabili dinamiche.\n",
    "\n",
    "IN langchain ci sono:\n",
    "- PromptTemplates (si possono utilizzare con qualsiasi LLM)\n",
    "- ChatPromptTemplates (da utilizzare per conversazioni con LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6af3ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate \n",
    "\n",
    "template = '''You are an expert vitologist. Write a few sentences about that virus {virus} in {language}'''\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "prompt = prompt_template.format(virus='hiv', language='italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be54834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert vitologist. Write a few sentences about that virus hiv in italian'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c5c3a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Il virus HIV, o Human Immunodeficiency Virus, è un virus che attacca e distrugge le cellule dell'immunosistema umano, causando la malattia dell'AIDS (Sindrome dell'Immunodeficienza Scompensata). È trasmesso principalmente attraverso il contatto sessuale non protetto con il sperma infettato, ma anche attraverso l'inoculazione di sangue infettato, l'inoculazione di farmaci infettati e attraverso la trasmissione verticale da madre a figlio durante il parto.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "        api_key='545454545',\n",
    "        base_url='http://localhost:8000/v1',\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f082790e",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "\n",
    "Si può utilizzare con OpenAI Chatcompletion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c2a1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in the JSON format.'), HumanMessage(content='Top 10 cities in  Italy by population order by population descending.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content = 'You respond only in the JSON format.'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} cities in  {country} by population order by population descending.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n = '10', country = 'Italy')\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdfc2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "\"cities\": [\n",
      "{\n",
      "\"name\": \"Milan\",\n",
      "\"population\": 2693959\n",
      "},\n",
      "{\n",
      "\"name\": \"Rome\",\n",
      "\"population\": 2833020\n",
      "},\n",
      "{\n",
      "\"name\": \"Naples\",\n",
      "\"population\": 2187475\n",
      "},\n",
      "{\n",
      "\"name\": \"Florence\",\n",
      "\"population\": 1792946\n",
      "},\n",
      "{\n",
      "\"name\": \"Torino\",\n",
      "\"population\": 2335695\n",
      "},\n",
      "{\n",
      "\"name\": \"Bologna\",\n",
      "\"population\": 1087936\n",
      "},\n",
      "{\n",
      "\"name\": \"Genoa\",\n",
      "\"population\": 874443\n",
      "},\n",
      "{\n",
      "\"name\": \"Venice\",\n",
      "\"population\": 268983\n",
      "},\n",
      "{\n",
      "\"name\": \"Pisa\",\n",
      "\"population\": 187234\n",
      "},\n",
      "{\n",
      "\"name\": \"Reggio Emilia\",\n",
      "\"population\": 159682\n",
      "}\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "        api_key='545454545',\n",
    "        base_url='http://localhost:8000/v1',\n",
    "        temperature=0\n",
    "    \n",
    "    )\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a8c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
