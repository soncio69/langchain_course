{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977de91a",
   "metadata": {},
   "source": [
    "In questo notebook proviamo a testare i Langchain Model I/O:\n",
    "- Prompts\n",
    "- Language Models\n",
    "- Output Parser\n",
    "\n",
    "Utilizzando sia OpenAI (utilizzando llamacpp fake server) e Huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c5b8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314e2d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e64fff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (0.22.2)\n",
      "Requirement already satisfied: filelock in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from huggingface_hub) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/michele/anaconda3/envs/langchain_env/lib/python3.12/site-packages (from requests->huggingface_hub) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5f478",
   "metadata": {},
   "source": [
    "Creo 2 diversi llm. \n",
    "\n",
    "Il primo utilizzando le API di OpenAI per connettermi con il local server llamacpp precedentemente attivato sul pc locale (python -m llama_cpp.server --model models/mistral-7b-instruct-v0.1.Q4_K_M.gguf dal environment llamacpp e dal repository del progetto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e237236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "#from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "        api_key='545454545',\n",
    "        base_url='http://localhost:8000/v1'\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e60ab",
   "metadata": {},
   "source": [
    "Il secondo connettendomi a Huggingface_hub utilizzando il token. In questo caso il modello non viene \"eseguito\" localmente ma da remoto e l'interazione avviene via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e70c6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/michele/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "huggingface_llm = HuggingFaceEndpoint(\n",
    "    repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    model_kwargs={\n",
    "        \"max_length\":4096,\n",
    "        \"token\":os.environ.get('HUGGINGFACEHUB_API_TOKEN'),\n",
    "    },\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c27cb",
   "metadata": {},
   "source": [
    "Creo un semplice prompt testuale da utilizzare per la chiamata al llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556e1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"How do I become an AI Engineer?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0fb667",
   "metadata": {},
   "source": [
    "L'llm si connette utilizzando l'API di OpenAI al server locale per creare la risposta alla domanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2fd0593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Becoming an AI Engineer typically requires a combination of education and experience in computer science, mathematics, and artificial intelligence. Here are some steps you can take to pursue a career as an AI Engineer:\n",
      "\n",
      "1. Obtain a bachelor's degree in computer science, mathematics, or a related field. A bachelor's degree is generally required for entry-level positions in the field.\n",
      "2. Consider earning a master's degree in artificial intelligence, machine learning, or a related field. A master's degree can provide additional knowledge and skills, and may be required for some advanced positions.\n",
      "3. Gain practical experience through internships or entry-level jobs in the field. This can help you gain hands-on experience with AI technologies and build your professional network.\n",
      "4. Consider earning professional certifications in AI or related fields. Certifications can demonstrate your expertise and knowledge, and may be required for some positions.\n",
      "5. Continuously update your skills through ongoing learning and professional development. The field of AI is rapidly evolving, and it's important to stay up-to-date with the latest developments and technologies.\n"
     ]
    }
   ],
   "source": [
    "openai_response = openai_llm.invoke(prompt)\n",
    "print(openai_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8fdba",
   "metadata": {},
   "source": [
    "L'llm si connette utilizzando l'API di Huggingface per creare la risposta alla domanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc50fd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "To become an AI Engineer, you typically need a strong foundation in computer science, mathematics, and programming. Here are some steps you can take to pursue a career in this field:\n",
      "\n",
      "1. Get a bachelor's degree in computer science, mathematics, engineering, or a related field. This will give you a solid foundation in the principles of computer science, mathematics, and programming, which are essential for working with AI systems.\n",
      "2. Gain experience in programming and data analysis. AI engineering involves working with large datasets and writing code to build and train machine learning models. Familiarize yourself with programming languages such as Python, R, or Java, and learn data analysis tools such as NumPy, Pandas, and Scikit-Learn.\n",
      "3. Learn about machine learning and deep learning. Machine learning and deep learning are the core technologies used in AI systems. Familiarize yourself with the fundamentals of these technologies, including supervised and unsupervised learning, neural networks, and deep learning architectures.\n",
      "4. Build a portfolio of projects. AI engineering is a highly competitive field, and having a strong portfolio of projects can help you stand out from other candidates. Build projects using open datasets, or work on projects for your employer or clients.\n",
      "5. Stay up-to-date with the latest developments in AI. AI is a rapidly evolving field, and it's important to stay informed about the latest developments and trends. Read industry publications, attend conferences, and engage with other professionals in the field to stay informed and expand your network.\n",
      "6. Consider pursuing a master's degree or PhD in computer science, machine learning, or a related field. While not required, advanced degrees can help you gain a deeper understanding of the underlying principles of AI and make you more competitive in the job market.\n",
      "7. Network and build relationships. Building relationships with other professionals in the field can help you learn new skills, find job opportunities, and stay informed about the latest developments in AI. Attend industry events, join professional organizations, and engage with other professionals on social media and online forums.\n",
      "8. Look for job opportunities. Once you have gained some experience and built a strong portfolio of projects, start looking for job opportunities. Look for job openings in companies that are working on AI projects, and tailor your resume and cover letter to highlight your relevant skills and experience.\n",
      "9. Continuously learn and improve. AI is\n"
     ]
    }
   ],
   "source": [
    "huggingface_response = huggingface_llm.invoke(prompt)\n",
    "print(huggingface_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd19b1",
   "metadata": {},
   "source": [
    "### Chat Models\n",
    "\n",
    "Basati su messages anzichè su prompt testuali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65efb0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La scelta di chi sia il miglior portiere del mondo è soggettiva e dipende da molti fattori, ma tra i più famosi e talentuosi portieri attualmente attivi, si possono citare: Gianluigi Buffon, David de Gea, Thibaut Courtois.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "        api_key='545454545',\n",
    "        base_url='http://localhost:8000/v1'\n",
    "    )\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Tu sei un esperto di calcio e devi consigliare i migliori giocatori\"),\n",
    "    HumanMessage(content=\"Chi è il miglior portiere del mondo?\")\n",
    "    \n",
    "]\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da30b4d",
   "metadata": {},
   "source": [
    "### PromptTenplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5344e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human: What is the capital of Italia?\n",
      "AI: The capital of Italia is Roma\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Human: What is the capital of {place}?\n",
    "AI: The capital of {place} is {capital}\n",
    "\"\"\")\n",
    "\n",
    "prompt = prompt_template.format(place=\"Italia\", capital=\"Roma\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a6e2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time in Parma, Italy, a young girl named Maria discovered her love for cooking while helping her grandmother prepare traditional Italian dishes. With passion and determination, she honed her skills and opened her own restaurant, which quickly became a local favorite and drew visitors from all over the region.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "template=\"Write a {lenght}\" story about: {content}\n",
    "\"\"\")\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    lenght=\"2 sentence\",\n",
    "    content=\"Parma\")\n",
    "\n",
    "response = chat.invoke(input=prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a8e22",
   "metadata": {},
   "source": [
    "### Output Parsers\n",
    "\n",
    "Servono per strutturare la risposta di un llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98406f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.output_parsers.list import ListOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2b839c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here are three sports that don't typically involve using a ball:\n",
      "1. Gymnastics - This sport focuses on body control, flexibility, strength, and agility, with athletes performing routines without the use of equipment.\n",
      "2. Martial Arts - Many martial arts styles, such as judo, karate, and Brazilian jiu-jitsu, do not require the use of a ball. Instead, they emphasize techniques for self-defense or combat.\n",
      "3. Yoga - Yoga is a mind-body practice that involves holding poses and practicing breathing exercises to promote physical and mental well-being. It does not require the use of a ball or any other equipment.\n"
     ]
    }
   ],
   "source": [
    "prompt=PromptTemplate.from_template(\"\"\"List 3 {things}\"\"\")\n",
    "\n",
    "response=chat.invoke(input=prompt.format(things=\"Sport that don't use the ball\"))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686b614",
   "metadata": {},
   "source": [
    "### Instantiate output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ecfc20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
     ]
    }
   ],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f97d0",
   "metadata": {},
   "source": [
    "Vediamo come usare le parser instructions nel prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f90a09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fencing, Swimming, Weightlifting\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"List 3 {things}.\\n{format_instructions}\",\n",
    "    input_variables=[\"things\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "#output = chat.predict(text=prompt.format(things=\"sports that don'i use the ball\"))\n",
    "output = chat.invoke(input=prompt.format(things=\"sports that don'i use the ball\"))\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded298f2",
   "metadata": {},
   "source": [
    "Convertiamo la lista in un python object (List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f0975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fencing', 'Swimming', 'Weightlifting']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a6c26",
   "metadata": {},
   "source": [
    "### Langchain Expression Language (LCEL)\n",
    "\n",
    "EXAMPLE = chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c711c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Golden light shining\\nBustling streets of Parma alive\\nSunny day, pure delight'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Write a rap haiku about {topic}\"\"\")\n",
    "output_parser = StrOutputParser\n",
    "\n",
    "chain = prompt | chat | output_parser()\n",
    "\n",
    "chain.invoke({\"topic\":\"sunny day in Parma\"})\n",
    "\n",
    "#chain.invoke(input=prompt.format(topic=\"sunny day in Parma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e91ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain_env]",
   "language": "python",
   "name": "conda-env-langchain_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
